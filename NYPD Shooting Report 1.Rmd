---
title: "NYPD Shooting Incident-Week3 Project"
author: "Your Friend in Class"
date: "03/06/2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Project Objective
The aim of this project is to investigate the connections between shooting incidents in New York and various factors, such as the time of day, day of the week, victim's race, age, and gender. The report will describe the steps taken to import and clean the data, as well as the visualization techniques used to analyze it. Additionally, the report will present a range of analyses based on both single and multiple variables. Finally, the report will summarize the key findings and discuss any potential biases in the data.

### Data Set Background
To begin analyzing data, it is crucial to comprehend its origin and content. The NPYD Shooting Incident Data (Historic) is accessible on NYC OpenData and comprises a comprehensive list of all shooting incidents that have taken place in NYC from 2006 up to the most recent calendar year. This data is reviewed by the Office of Management Analysis and Planning and includes details such as the time, location, and information about the event, as well as suspect and victim demographics. The data is available for public use and can be utilized to investigate the nature of criminal activities related to shootings.

Due to the assignment's requirements to show all code from each R Markdown block, all of the code results are placed in this document as well. 
Since the assignment mandates displaying all R Markdown block code, this document also includes the results generated by the code.

### Part 1 : Loading libraries and importing the data
<br>
#### 1.1 Loading necessary packages
We will load R's tidyverse library, which contains useful packages such as ggplot2 and tidyr. We will also load lubridate for date-time.
```{r package loading, message = FALSE, warning = FALSE}
library(tidyverse)
library(lubridate)
library(anytime)
library(randomForest)
```
<br>
#### 1.2 Importing the data set
The data is downloaded from NYPD OpenData. The data file is in csv format. 

```{r data import, results = 'hide', message = FALSE}
data_url_in <- "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
raw_data <- read_csv(data_url_in)
```

### Part II :  Data Exploration & data wrangling & tidying : 
**This is the main objectives from this section** 
- Understand the shape and dimensions of the data
- Explore variables in data sets 
- Know the variable types to know if conversion is necessary or not  
- Identify any missing values 
- Clean and prepare the data set by fixing up data types, and dealing with missing values.

Below are the steps we are takedn to achieve these objectives 

#### 1. Understanding the structure, and dimensions
```{r data structure, message = FALSE}
str(raw_data)
```

We can see that there are 23568 rows x 19 columns (variables)

To have a closer look at the data, we can view() or head(). For now let's have a look at the first 6 rows. 
```{r head}
head(raw_data)
```

Let's also take a look at a random sample of 8 rows, just to get an idea and have more understanding 
```{r sample rows}
sample_n(raw_data, 8)
```

We can also take a look at the summary statistics of the data, noting that no summaries for character variables.
```{r initial summary stats}
summary(raw_data)
```

#### 2. Exploring the variables
The most important step is to understand what the variables, and what they actually represent. It is often best to first look up the official description. For our data set, the official description can be found here: https://data.cityofnewyork.us/Public-Safety/NYPD-Shooting-Incident-Data-Historic-/833y-fsy8

Column Name|Description
:----------|:----------|
INCIDENT_KEY| Randomly generated persistent ID for each arrest
OCCUR_DATE|Exact date of the shooting incident
OCCUR_TIME|Exact time of the shooting incident
BORO|Borough where the shooting incident occurred
PRECINCT|Precinct where the shooting incident occurred
JURISDICTION_CODE|Jurisdiction where the shooting incident occurred. Jurisdiction codes 0(Patrol), 1(Transit) and 2(Housing) represent NYPD whilst codes 3 and more represent non NYPD jurisdictions
LOCATION_DESC|Location of the shooting incident
STATISTICAL_MURDER_FLAG|Shooting resulted in the victim’s death which would be counted as a murder
PERP_AGE_GROUP|Perpetrator’s age within a category
PERP_SEX|Perpetrator’s sex description
PERP_RACE|Perpetrator’s race description
VIC_AGE_GROUP|Victim’s age within a category
VIC_SEX|Victim’s sex description
VIC_RACE|Victim’s race description
X_COORD_CD|Midblock X-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104)
Y_COORD_CD|Midblock Y-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104)
Latitude|Latitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326)
Longitude|Longitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326)
Lon_Lat|Longitude and Latitude Coordinates for mapping

******Observation & Discussion**

Based on these definitions, we can drop the variables and columns that we are not interested in. For this particular project, I am not particularly interested in the INCIDENT_KEY, PRECINCT, JURISDICTION_CODE, LOCATION_DESC, X_COORD_CD, Y_COORD_CD, Latitude, Longitude and Lon_Lat.

**Data Cleaning - Dropping ( Columns not needed for analysis  )**   

```{r subsetting data for analysis}
raw_data <- raw_data %>% select(OCCUR_DATE, OCCUR_TIME, BORO, STATISTICAL_MURDER_FLAG, PERP_AGE_GROUP, PERP_SEX, PERP_RACE, VIC_AGE_GROUP, VIC_SEX, VIC_RACE)
```

Let's have a look at this subset of data
```{r}
str(raw_data)
```
#### 3. Do we need pivoting using long pivot or wide pivoty ?  

Each variable having its own column and each ****Observation & Discussion** & Discssion** (shooting incident) having its own row. Therefore, it is R friendly in this manner 


#### 4. Exploring missing values
```{r Missing}
sapply(raw_data, function(x) sum(is.na(x)))
```

**Observation & Discussion**

It seems we have missing values in
- PERP_AGE_GROUP
- PERP_SEX 
- PERP_RACE columns.

**Data Cleaning  ** 
For this we can : 
- Impute the missing values by filling up the missing values with the mode.
- Drop all columns with missing values & this is what we did .

**Important point**
Sometimes missing data could be happening for a reason and an important insight can be obtained by contacting data honer about why data is missing 

```{r}
new_data <- subset(raw_data, select = -c(PERP_AGE_GROUP, PERP_SEX, PERP_RACE))
```

#### 5. Exploring data types & data minipulation and wrangling 
As we can see from the previous sections, there are several variables whose types (classes) seem rather suspicious.

For example, OCCUR_DATE should be date-time, while STATISTICAL_MURDER_FLAG can be converted to chr type for better interpretation.

**Converting data types**
  - Convert char data types into factor 
 


```{r fixing data type}
new_data$OCCUR_DATE <- anytime(new_data$OCCUR_DATE)
new_data$STATISTICAL_MURDER_FLAG <- as.character(new_data$STATISTICAL_MURDER_FLAG)
new_data <- new_data %>% mutate_if(is.character,as.factor)
```

**Data wrangling & manipulating - Combining data **

We can also combine OCCUR_DATE and OCCUR_TIME into OCCUR_DATETIME, and drop the original two columns
```{r combine date and time}
new_data$OCCUR_DATETIME <- with(new_data, anytime(paste(OCCUR_DATE, OCCUR_TIME)))
new_data <- subset(new_data, select = -c(OCCUR_DATE, OCCUR_TIME))
str(new_data)
```
<br>
<br>

### Part III: Exploratory Data Analysis
#### 1. Univariate Analysis
Univariate analysis is a statistical analysis technique that focuses on examining a single variable at a time. In other words, it involves the analysis of a single variable's characteristics, such as its distribution, central tendency, and dispersion.

**Where do shootings tend to happen?**
```{r}
table(new_data$BORO)
new_data %>% ggplot(aes(BORO)) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Borough") + ylab("Shooting Incident Count") 
```

**Observation & Discussion**
Observing the number of shootings, it's evident that Brooklyn has the most occurrences. However, we cannot infer that Brooklyn is more hazardous than Staten Island based solely on this data. It's possible that Brooklyn's population is much larger than that of Staten Island, which could explain the higher number of shootings.A better way of looking at this is to maybe also check population and percentage out of this population . 


**Relation of gender & shooting incidents**
```{r}
table(new_data$VIC_SEX)
new_data %>% ggplot(aes(VIC_SEX)) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Sex") + ylab("Shooting Incident Count")
```

**Observation & Discussion**
We can see that men are much more likely to be involved in shooting incidents as victims than women. We might wanna need to look if these events are actually combined with some kind of sexual assaults or not to get more insights . 

**How are victim age groups related to shooting incidents?**
```{r}
table(new_data$VIC_AGE_GROUP)
new_data %>% ggplot(aes(VIC_AGE_GROUP)) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Age Group") + ylab("Shooting Incident Count")
```

**Observation & Discussion**

It is evident that a significant number of shooting victims fall within the age brackets of 18-24 and 25-44, which aligns with my intuition that younger individuals tend to engage in more risky behavior and are more prone to getting involved in altercations with others.This is could me me just being biased . 

**victim races relation to shooting incidents**
```{r}
table(new_data$VIC_RACE)
new_data %>% ggplot(aes(VIC_RACE)) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Race") + ylab("Shooting Incident Count")+ theme(axis.text.x = element_text(angle = 90))
```

**Observation & Discussion** 

We can observe that a disproportionately large count of shooting incident victims are Black, followed by White Hispanic and Black Hispanic.


**How is the day of the week related to shooting incidents?**
```{r}
Sys.setlocale("LC_TIME", "English")
new_data %>% ggplot(aes(wday(OCCUR_DATETIME, label = TRUE, week_start = 1))) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Day of the Week") + ylab("Shooting Incident Count") + xlab("Days of the week")
```

**Observation & Discussion**

As anticipated, the frequency of shootings is higher during weekends. This trend could potentially be attributed to increased alcohol consumption during weekends; however, this assumption may not be entirely valid, and further data analysis may be required to confirm or refute this hypothesis.

**How is the time of the day related to shooting incidents?**
```{r}
Sys.setlocale("LC_TIME", "English")
new_data %>% ggplot(aes(hour(OCCUR_DATETIME))) + geom_bar() + theme_classic() + ggtitle("Shooting Incident Count by Time of the Day") + ylab("Shooting Incident Count") + xlab("Time of the Day")
```

**Observation & Discussion**

Shootings frequently occur during the late-night to early morning period, particularly between 11 pm to 1 am, which is also when alcohol consumption tends to be at its highest.

Moreover, this time frame aligns with the age demographics we previously identified, with more individuals between the ages of 18-44 being present on the streets compared to younger or older age groups.

**Are there any trends in shooting incidents throughout the years?**
```{r}
new_data <- new_data %>% mutate(year_month = format_ISO8601(OCCUR_DATETIME, precision = "ym"))
monthly_shooting <- new_data %>% group_by(year_month) %>% summarize(monthly_incidents = n())
monthly_shooting %>% ggplot(aes(x = year_month, y = monthly_incidents, group =1, label = year_month)) + geom_line() + geom_text(size = 2, color = 'blue') + theme_classic() +  theme(axis.text.x=element_blank()) + xlab("Time (in month)") + ylab("Total Monthly Shooting Incidents") + ggtitle("Monthly Shooting Incidents over Time")
```

#### 2. Multivariate Analysis
Multivariate analysis is a statistical technique used to analyze data sets that contain more than one dependent variable. It involves examining the relationships between multiple variables, identifying patterns and trends, and making predictions based on those patterns.

**Age group and time of the day**
```{r}
new_data %>% ggplot(aes(hour(OCCUR_DATETIME), fill = factor(VIC_AGE_GROUP))) + geom_bar(position = 'fill') + theme_classic() + ggtitle("Shooting Incident: Shooting Proportion vs Time of the Day") + ylab("Shooting Incident Proportion") + xlab("Time of the Day")
```

**Observation & Discussion**

We can see quite clearly from the bar graph above, 18-24, 25-44 dominate the proportion of victims throughout all hours the day, but they make up an even greater proportion at late nights and early morning. These observations are consistent with our previous expectations.

**Borough and day of the week**
```{r}
new_data %>% ggplot(aes(wday(OCCUR_DATETIME, label = TRUE, week_start = 1), fill = factor(BORO))) + geom_bar(position = 'fill') + theme_classic() + ggtitle("Shooting Incident Proportion by Day of the Week") + ylab("Shooting Incident Proportion") + xlab("Day of the Week")
```

**Observation & Discussion**

We see that the proportion of shootings in Bronx tends to rise over the week, while for Brooklyn we tend to see higher proportions of shootings on Mondays and Tuesdays.

### Section IV: Modelling
####"STATISTICAL_MURDER_FLAG" Prediction via random forest model **
In this section, we shall try to predict the "STATISTICAL_MURDER_FLAG", TRUE refers to shooting resulted in the victim’s death which would be counted as a murder, and FALSE means that the incident did not count as a murder.

**Class Imbalance**
Class imbalance in variable analysis refers to the situation where the distribution of target classes in a dataset is highly skewed towards one class (referred to as the majority class) and has significantly fewer observations in the other class (referred to as the minority class). This issue is common in many real-world applications such as fraud detection, disease diagnosis, and rare event prediction.


**How imbalanced is the "STATISTICAL_MURDER_FLAG" variable?**
```{r}
prop.table(table(new_data$STATISTICAL_MURDER_FLAG))
```
We have about a 1:4 ratio between TRUE and FALSE, which is slightly imbalanced. For this project, we will not use oversampling or undersampling methods to deal with class imbalance.

**Splitting the data into train and validation sets**
```{r train val split}
set.seed(42)
# Splitting the data into 75% training, and 25% validation
indexes <- sample(1:nrow(new_data), size = 0.75*nrow(new_data))
training <- new_data[indexes,]
validation <- new_data[-indexes,]
```

**Building a random forest model**
Random forest is a powerful machine learning technique. It can be used for classification or regression problems. In this project, we will use default settings for the random forest model.
```{r}
rf_clf = randomForest(STATISTICAL_MURDER_FLAG ~ ., data=training)
rf_clf
```
We achieved an error rate of only 19%, not bad! 

Wait wait wait, 
if we look at the results more closely, our model is in fact severely overfitting the data, and basically it is predicting FALSE for all observation, thus resulting in a very high number of false negatives! This is a classic problem with imbalanced classes, and requires further data wrangling to fix the issues.

**Remember , our objective here not to do the perfect analsis byut rather do th enalsis and understand why its not perfect **


### Section V: Conclusion and further questions to explore
As we have discovered, shootings tend to happen most frequently:

* On weekends
* From 11pm - 1am(next day)
* In Brooklyn and Bronx
* To the Black ethnicity
* To people aged between 18-44
* To men

#### 1. Further Question to Explore
I have been using alcohol consumption a key factor for explaining the pattern above. However, this is only a hypothesis and since this data set does not contain relevant alcohol consumption information, we have to look into other data sets to find evidence for verifying our hypothesis.

Furthermore, we will need to use more sophisticated data wrangling methods to deal with the imbalanced class problem, in order to generate a more meaningful model. After re-modeling, we will be able to make use of our validation data set and determine how well our predictions would generalize to new data.

#### 2. Exploring Potential Biases
Sometimes, it is crucial to consider the gaps in the data rather than solely focusing on the information it provides. By "gaps" in the data, I mean the narratives and conclusions that arise not from the data itself but from our own subjective interpretations and biases.

As an individual, I have personal views against alcoholism that may influence my perceptions and lead to cognitive biases such as heuristics and confirmation bias, where I may interpret any data patterns as confirming my own beliefs, regardless of whether the data supports them or not.

Moreover, there may be other confounding factors, apart from alcohol consumption, that can explain the observed trends. For instance, socio-economic status could play a critical role. People other than "party animals" might be out on the streets at midnight, such as homeless individuals, taxi drivers, and convenience store sales assistants who tend to be younger in age (18-44) as it gets more difficult to work night shifts as one gets older.

To mitigate biases, it is essential to incorporate diverse perspectives and be inclusive. For instance, peer reviews can introduce new viewpoints, and discussing the findings with domain experts can help identify common flaws in logic and pitfalls in our analysis. Additionally, conducting research on similar studies and papers through online resources like Google can offer a useful checklist for our analysis by highlighting past biases raised by researchers.


```{r}
sI <- sessionInfo()
print(sI, locale = FALSE)
```
